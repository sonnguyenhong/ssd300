{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f3660ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run lib.ipynb\n",
    "%run utils/box_utils.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0b584037",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiBoxLoss(torch.nn.Module):\n",
    "    def __init__(self, jaccard_threshold=0.5, neg_pos=3, device=\"cpu\"):\n",
    "        super(MultiBoxLoss, self).__init__()\n",
    "        self.jaccard_threshold = jaccard_threshold\n",
    "        self.neg_pos = neg_pos\n",
    "        self.device = device\n",
    "        \n",
    "    def forward(self, predictions, targets):\n",
    "        loc_data, conf_data, dbox_list = predictions\n",
    "        \n",
    "        # conf_data (batch_num, num_dbox, num_classes)\n",
    "        num_batch = loc_data.size(0)\n",
    "        num_dbox = loc_data.size(1)\n",
    "        num_classes = conf_data.size(2)\n",
    "        \n",
    "        conf_t_label = torch.LongTensor(num_batch, num_dbox).to(self.device)\n",
    "        loc_t = torch.Tensor(num_batch, num_dbox, 4).to(self.device)\n",
    "        \n",
    "        for idx in range(num_batch):\n",
    "            truths = targets[idx][:, :-1].to(self.device) # [xmin, ymin, xmax, ymax] BBox\n",
    "            labels = targets[idx][:, -1].to(self.device)  # labels\n",
    "            \n",
    "            dbox = dbox_list.to(self.device)\n",
    "            variances = [0.1, 0.2]\n",
    "            \n",
    "            match(self.jaccard_threshold, truths, dbox, variances, labels, loc_t, conf_t_label, idx)\n",
    "            \n",
    "        # SmoothL1Loss\n",
    "        pos_mask = conf_t_label > 0\n",
    "        # loc_data(num_batch, 8732, 4)\n",
    "        pos_idx = pos_mask.unsqueeze(pos_mask.dim()).expand_as(loc_data)\n",
    "        \n",
    "        # positive default box, loc_data\n",
    "        loc_p = loc_data[pos_idx].view(-1, 4)\n",
    "        loc_t = loc_t[pos_idx].view(-1, 4)\n",
    "        \n",
    "        loss_loc = F.smooth_l1_loss(loc_p, loc_t, reduction=\"sum\")\n",
    "        \n",
    "        # loss_conf (use cross entropy)\n",
    "        batch_conf = conf_data.view(-1, num_classes)  # (num_batch, num_box, num_classes) --> (-1, num_classes)\n",
    "        \n",
    "        loss_conf = F.cross_entropy(batch_conf, conf_t_label.view(-1), reduction=\"none\")\n",
    "        \n",
    "        # hard negative mining\n",
    "        num_pos = pos_mask.long().sum(1, keepdim=True)\n",
    "        loss_conf = loss_conf.view(num_batch, -1) # --> size: torch.size([num_batch, 8732])\n",
    "        \n",
    "        _, loss_idx = loss_conf.sort(1, descending=True)\n",
    "        _, idx_rank = loss_idx.sort(1)\n",
    "        # idx_rank la thong so de biet duoc do lon loss nam o vi tri bao nhieu\n",
    "        \n",
    "        num_neg = torch.clamp(num_pos * self.neg_pos, max=num_dbox)\n",
    "        neg_mask = idx_rank < (num_neg).expand_as(idx_rank)\n",
    "        \n",
    "        # (num_batch, 8732) ==> (num_batch, 8732, 21)\n",
    "        pos_idx_mask = pos_mask.unsqueeze(2).expand_as(conf_data)\n",
    "        neg_idx_mask = neg_mask.unsqueeze(2).expand_as(conf_data)\n",
    "        \n",
    "        conf_t_pred = conf_data[(pos_idx_mask + neg_idx_mask).gt(0)].view(-1, num_classes)   # predictions of netword\n",
    "        \n",
    "        conf_t_label_ = conf_t_label[(pos_mask + neg_mask).gt(0)]    # our labels\n",
    "        \n",
    "        loss_conf = F.cross_entropy(conf_t_pred, conf_t_label_, reduction=\"sum\")\n",
    "        \n",
    "        # total loss = loss_loc + loss_conf\n",
    "        \n",
    "        N = num_pos.sum()\n",
    "        loss_loc = loss_loc / N\n",
    "        loss_conf = loss_conf / N\n",
    "        \n",
    "        return loss_loc, loss_conf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3483969d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
