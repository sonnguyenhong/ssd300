{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03038747",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run lib.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7048ab85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5717\n",
      ".\\data\\VOCdevkit\\VOC2012\\JPEGImages\\2008_000008.jpg\n"
     ]
    }
   ],
   "source": [
    "%run make_datapath.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "baf4bda6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5717\n",
      ".\\data\\VOCdevkit\\VOC2012\\JPEGImages\\2008_000008.jpg\n",
      "5717\n",
      ".\\data\\VOCdevkit\\VOC2012\\JPEGImages\\2008_000008.jpg\n",
      "[[ 0.09        0.03003003  0.998       0.996997   18.        ]\n",
      " [ 0.122       0.56756757  0.164       0.72672673 14.        ]]\n",
      "5717\n",
      ".\\data\\VOCdevkit\\VOC2012\\JPEGImages\\2008_000008.jpg\n",
      "[[ 0.09        0.03003003  0.998       0.996997   18.        ]\n",
      " [ 0.122       0.56756757  0.164       0.72672673 14.        ]]\n",
      "torch.Size([4, 3, 300, 300])\n",
      "4\n",
      "torch.Size([1, 5])\n"
     ]
    }
   ],
   "source": [
    "%run dataset.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df35419f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5717\n",
      ".\\data\\VOCdevkit\\VOC2012\\JPEGImages\\2008_000008.jpg\n",
      "5717\n",
      ".\\data\\VOCdevkit\\VOC2012\\JPEGImages\\2008_000008.jpg\n",
      "[[ 0.09        0.03003003  0.998       0.996997   18.        ]\n",
      " [ 0.122       0.56756757  0.164       0.72672673 14.        ]]\n"
     ]
    }
   ],
   "source": [
    "%run transform.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9c41a13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5717\n",
      ".\\data\\VOCdevkit\\VOC2012\\JPEGImages\\2008_000008.jpg\n",
      "[[ 0.09        0.03003003  0.998       0.996997   18.        ]\n",
      " [ 0.122       0.56756757  0.164       0.72672673 14.        ]]\n"
     ]
    }
   ],
   "source": [
    "%run extract_infor_annotation.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82dee7ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8732, 4])\n",
      "SSD(\n",
      "  (vgg): ModuleList(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU(inplace=True)\n",
      "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU(inplace=True)\n",
      "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU(inplace=True)\n",
      "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): ReLU(inplace=True)\n",
      "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (20): ReLU(inplace=True)\n",
      "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (22): ReLU(inplace=True)\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): ReLU(inplace=True)\n",
      "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (27): ReLU(inplace=True)\n",
      "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (29): ReLU(inplace=True)\n",
      "    (30): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "    (31): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6))\n",
      "    (32): ReLU(inplace=True)\n",
      "    (33): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (34): ReLU(inplace=True)\n",
      "  )\n",
      "  (extras): ModuleList(\n",
      "    (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (2): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (3): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (4): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (5): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (6): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (7): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "  )\n",
      "  (loc): ModuleList(\n",
      "    (0): Conv2d(512, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): Conv2d(1024, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (2): Conv2d(512, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): Conv2d(256, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): Conv2d(256, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (5): Conv2d(256, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (conf): ModuleList(\n",
      "    (0): Conv2d(512, 84, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): Conv2d(1024, 126, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (2): Conv2d(512, 126, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): Conv2d(256, 126, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): Conv2d(256, 84, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (5): Conv2d(256, 84, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (L2Norm): L2Norm()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "%run model.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bbfab93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run multiboxloss.ipynb\n",
    "%run utils/augmentation.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23d6fca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device:\", device)\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1227e9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloader\n",
    "root_path = \"./data/VOCdevkit/VOC2012\"\n",
    "train_img_list, train_anno_list, val_img_list, val_anno_list = make_datapath_list(root_path)\n",
    "\n",
    "classes = [\"aeroplane\", \"bicycle\", \"bird\",  \"boat\", \"bottle\", \n",
    "    \"bus\", \"car\", \"cat\", \"chair\", \"cow\", \"diningtable\",\n",
    "    \"dog\", \"horse\", \"motorbike\", \"person\", \"pottedplant\",\n",
    "    \"sheep\", \"sofa\", \"train\", \"tvmonitor\"]\n",
    "\n",
    "color_mean = (104, 117, 123)\n",
    "input_size = 300\n",
    "\n",
    "#img_list, anno_list, phase, transform, anno_xml\n",
    "train_dataset = MyDataset(train_img_list, train_anno_list, phase=\"train\", transform=DataTransform(input_size, color_mean), anno_xml=Anno_xml(classes))\n",
    "val_dataset = MyDataset(val_img_list, val_anno_list, phase=\"val\", transform=DataTransform(input_size, color_mean), anno_xml=Anno_xml(classes))\n",
    "\n",
    "batch_size = 32\n",
    "train_dataloader = data.DataLoader(train_dataset, batch_size, shuffle=True, collate_fn=my_collate_fn)\n",
    "val_dataloader = data.DataLoader(val_dataset, batch_size, shuffle=False, collate_fn=my_collate_fn)\n",
    "dataloader_dict = {\n",
    "    \"train\": train_dataloader, \n",
    "    \"val\": val_dataloader\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "05c19503",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# network\n",
    "cfg = {\n",
    "    \"num_classes\": 21, #VOC data include 20 class + 1 background class\n",
    "    \"input_size\": 300, #SSD300\n",
    "    \"bbox_aspect_num\": [4, 6, 6, 6, 4, 4], # Tỷ lệ khung hình cho source1->source6`\n",
    "    \"feature_maps\": [38, 19, 10, 5, 3, 1],\n",
    "    \"steps\": [8, 16, 32, 64, 100, 300], # Size of default box\n",
    "    \"min_size\": [30, 60, 111, 162, 213, 264], # Size of default box\n",
    "    \"max_size\": [60, 111, 162, 213, 264, 315], # Size of default box\n",
    "    \"aspect_ratios\": [[2], [2,3], [2,3], [2,3], [2], [2]]\n",
    "}\n",
    "\n",
    "net = SSD(phase=\"train\", cfg=cfg)\n",
    "vgg_weights = torch.load(\"./data/weights/vgg16_reducedfc.pth\")\n",
    "net.vgg.load_state_dict(vgg_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "07f9a6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        nn.init.kaiming_normal_(m.weight.data)\n",
    "        if m.bias is not None:\n",
    "            nn.init.constant_(m.bias, 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b4db8c53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleList(\n",
       "  (0): Conv2d(512, 84, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (1): Conv2d(1024, 126, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (2): Conv2d(512, 126, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (3): Conv2d(256, 126, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (4): Conv2d(256, 84, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (5): Conv2d(256, 84, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# He init\n",
    "net.extras.apply(weights_init)\n",
    "net.loc.apply(weights_init)\n",
    "net.conf.apply(weights_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "04eae9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MultiBoxLoss\n",
    "criterion = MultiBoxLoss(jaccard_threshold=0.5, neg_pos=3, device=device)\n",
    "\n",
    "# optimizer\n",
    "optimizer = optim.SGD(net.parameters(), lr=1e-3, momentum=0.9, weight_decay=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b645a80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training, validation\n",
    "def train_model(net, dataloader_dict, criterion, optimizer, num_epochs):\n",
    "    # move network to GPU\n",
    "    net.to(device)\n",
    "\n",
    "    iteration = 1\n",
    "    epoch_train_loss = 0.0\n",
    "    epoch_val_loss = 0.0\n",
    "    logs = []\n",
    "    for epoch in range(num_epochs+1):\n",
    "        t_epoch_start = time.time()\n",
    "        t_iter_start = time.time()\n",
    "        print(\"---\"*20)\n",
    "        print(\"Epoch {}/{}\".format(epoch+1, num_epochs))\n",
    "        print(\"---\"*20)\n",
    "        for phase in [\"train\", \"val\"]:\n",
    "            if phase == \"train\":\n",
    "                net.train()\n",
    "                print(\"(Training)\")\n",
    "            else:\n",
    "                if (epoch+1) % 10 == 0:\n",
    "                    net.eval() \n",
    "                    print(\"---\"*10)\n",
    "                    print(\"(Validation)\")\n",
    "                else:\n",
    "                    continue\n",
    "            for images, targets in dataloader_dict[phase]:\n",
    "                # move to GPU\n",
    "                images = images.to(device)\n",
    "                targets = [ann.to(device) for ann in targets]\n",
    "                # init optimizer\n",
    "                optimizer.zero_grad()\n",
    "                # forward\n",
    "                with torch.set_grad_enabled(phase==\"train\"):\n",
    "                    outputs = net(images)\n",
    "                    loss_l, loss_c = criterion(outputs, targets)\n",
    "                    loss = loss_l + loss_c\n",
    "\n",
    "                    if phase == \"train\":\n",
    "                        loss.backward() # calculate gradient\n",
    "                        nn.utils.clip_grad_value_(net.parameters(), clip_value=2.0)\n",
    "                        optimizer.step() # update parameters\n",
    "\n",
    "                        if (iteration % 10) == 0:\n",
    "                            t_iter_end = time.time()\n",
    "                            duration = t_iter_end - t_iter_start\n",
    "                            print(\"Iteration {} || Loss: {:.4f} || 10iter: {:.4f} sec\".format(iteration, loss.item(), duration))\n",
    "                            t_iter_start = time.time()\n",
    "                        epoch_train_loss += loss.item()\n",
    "                        iteration += 1\n",
    "                    else:\n",
    "                        epoch_val_loss += loss.item()\n",
    "        t_epoch_end = time.time()\n",
    "        print(\"---\"*20)\n",
    "        print(\"Epoch {} || epoch_train_loss: {:.4f} || Epoch_val_loss: {:.4f}\".format(epoch+1, epoch_train_loss, epoch_val_loss))           \n",
    "        print(\"Duration: {:.4f} sec\".format(t_epoch_end - t_epoch_start))\n",
    "        t_epoch_start = time.time()\n",
    "\n",
    "        log_epoch = {\"epoch\": epoch+1, \"train_loss\": epoch_train_loss, \"val_loss\": epoch_val_loss}\n",
    "        logs.append(log_epoch)\n",
    "        df = pd.DataFrame(logs)\n",
    "        df.to_csv(\"./data/ssd_logs.csv\")\n",
    "        epoch_train_loss = 0.0\n",
    "        epoch_val_loss = 0.0\n",
    "        if ((epoch+1) % 10 == 0):\n",
    "            torch.save(net.state_dict(), \"./data/weights/ssd300_\" + str(epoch+1) + \".pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff412caa",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "Epoch 1/30\n",
      "------------------------------------------------------------\n",
      "(Training)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:238: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 10 || Loss: 13.9786 || 10iter: 590.7018 sec\n",
      "Iteration 20 || Loss: 11.8258 || 10iter: 470.5018 sec\n",
      "Iteration 30 || Loss: 11.9142 || 10iter: 454.1413 sec\n",
      "Iteration 40 || Loss: 10.0509 || 10iter: 485.2065 sec\n",
      "Iteration 50 || Loss: 8.4861 || 10iter: 501.8508 sec\n",
      "Iteration 60 || Loss: 7.7305 || 10iter: 5503.9769 sec\n",
      "Iteration 70 || Loss: 8.0202 || 10iter: 453.5588 sec\n",
      "Iteration 80 || Loss: 7.5931 || 10iter: 3277.7980 sec\n",
      "Iteration 90 || Loss: 7.9180 || 10iter: 610.3388 sec\n",
      "Iteration 100 || Loss: 7.9220 || 10iter: 600.7255 sec\n",
      "Iteration 110 || Loss: 7.4615 || 10iter: 527.5931 sec\n",
      "Iteration 120 || Loss: 7.4421 || 10iter: 570.6170 sec\n",
      "Iteration 130 || Loss: 7.5919 || 10iter: 589.7096 sec\n",
      "Iteration 140 || Loss: 7.6607 || 10iter: 546.1700 sec\n",
      "Iteration 150 || Loss: 7.0752 || 10iter: 529.7249 sec\n",
      "Iteration 160 || Loss: 8.2080 || 10iter: 448.2675 sec\n",
      "Iteration 170 || Loss: 8.8018 || 10iter: 448.8072 sec\n",
      "------------------------------------------------------------\n",
      "Epoch 1 || epoch_train_loss: 1649.8066 || Epoch_val_loss: 0.0000\n",
      "Duration: 17000.2642 sec\n",
      "------------------------------------------------------------\n",
      "Epoch 2/30\n",
      "------------------------------------------------------------\n",
      "(Training)\n",
      "Iteration 180 || Loss: 8.1318 || 10iter: 43.7287 sec\n",
      "Iteration 190 || Loss: 7.2438 || 10iter: 506.7360 sec\n",
      "Iteration 200 || Loss: 7.2719 || 10iter: 489.0254 sec\n",
      "Iteration 210 || Loss: 7.3572 || 10iter: 542.3655 sec\n",
      "Iteration 220 || Loss: 7.7027 || 10iter: 510.7581 sec\n",
      "Iteration 230 || Loss: 7.1026 || 10iter: 546.2045 sec\n",
      "Iteration 240 || Loss: 7.0504 || 10iter: 473.5813 sec\n",
      "Iteration 250 || Loss: 7.0893 || 10iter: 481.9501 sec\n",
      "Iteration 260 || Loss: 7.1214 || 10iter: 475.2217 sec\n",
      "Iteration 270 || Loss: 7.5887 || 10iter: 462.9350 sec\n",
      "Iteration 280 || Loss: 6.9979 || 10iter: 451.3122 sec\n",
      "Iteration 290 || Loss: 7.1080 || 10iter: 444.8787 sec\n",
      "Iteration 300 || Loss: 6.4359 || 10iter: 443.8805 sec\n",
      "Iteration 310 || Loss: 6.9727 || 10iter: 450.6423 sec\n",
      "Iteration 320 || Loss: 7.4941 || 10iter: 437.6200 sec\n",
      "Iteration 330 || Loss: 7.4753 || 10iter: 447.6949 sec\n",
      "Iteration 340 || Loss: 7.0518 || 10iter: 439.3225 sec\n",
      "Iteration 350 || Loss: 6.6630 || 10iter: 438.8509 sec\n",
      "------------------------------------------------------------\n",
      "Epoch 2 || epoch_train_loss: 1308.7023 || Epoch_val_loss: 0.0000\n",
      "Duration: 8423.3918 sec\n",
      "------------------------------------------------------------\n",
      "Epoch 3/30\n",
      "------------------------------------------------------------\n",
      "(Training)\n",
      "Iteration 360 || Loss: 7.1667 || 10iter: 87.6290 sec\n",
      "Iteration 370 || Loss: 7.4962 || 10iter: 439.5008 sec\n",
      "Iteration 380 || Loss: 6.7585 || 10iter: 442.2554 sec\n",
      "Iteration 390 || Loss: 6.8881 || 10iter: 439.2237 sec\n",
      "Iteration 400 || Loss: 7.2322 || 10iter: 439.6125 sec\n",
      "Iteration 410 || Loss: 7.3320 || 10iter: 438.9335 sec\n",
      "Iteration 420 || Loss: 6.6390 || 10iter: 438.5288 sec\n",
      "Iteration 430 || Loss: 7.0474 || 10iter: 436.7846 sec\n",
      "Iteration 440 || Loss: 6.5716 || 10iter: 440.1676 sec\n",
      "Iteration 450 || Loss: 6.6482 || 10iter: 438.3942 sec\n",
      "Iteration 460 || Loss: 6.5161 || 10iter: 441.2287 sec\n",
      "Iteration 470 || Loss: 6.5315 || 10iter: 437.2409 sec\n",
      "Iteration 480 || Loss: 6.7035 || 10iter: 438.7763 sec\n",
      "Iteration 490 || Loss: 7.4042 || 10iter: 438.0739 sec\n",
      "Iteration 500 || Loss: 6.4565 || 10iter: 439.2639 sec\n",
      "Iteration 510 || Loss: 6.6448 || 10iter: 438.0875 sec\n",
      "Iteration 520 || Loss: 6.6692 || 10iter: 438.8025 sec\n",
      "Iteration 530 || Loss: 6.4930 || 10iter: 435.8348 sec\n",
      "------------------------------------------------------------\n",
      "Epoch 3 || epoch_train_loss: 1215.6965 || Epoch_val_loss: 0.0000\n",
      "Duration: 7842.5981 sec\n",
      "------------------------------------------------------------\n",
      "Epoch 4/30\n",
      "------------------------------------------------------------\n",
      "(Training)\n",
      "Iteration 540 || Loss: 6.3582 || 10iter: 132.4652 sec\n",
      "Iteration 550 || Loss: 6.2169 || 10iter: 439.6896 sec\n",
      "Iteration 560 || Loss: 6.8566 || 10iter: 439.5743 sec\n",
      "Iteration 570 || Loss: 6.4005 || 10iter: 439.4009 sec\n",
      "Iteration 580 || Loss: 6.6981 || 10iter: 439.4313 sec\n",
      "Iteration 590 || Loss: 6.3402 || 10iter: 440.1005 sec\n",
      "Iteration 600 || Loss: 6.6739 || 10iter: 454.6336 sec\n",
      "Iteration 610 || Loss: 6.7102 || 10iter: 441.2576 sec\n",
      "Iteration 620 || Loss: 6.2306 || 10iter: 442.4958 sec\n",
      "Iteration 630 || Loss: 6.3211 || 10iter: 441.7174 sec\n",
      "Iteration 640 || Loss: 6.2763 || 10iter: 437.9137 sec\n",
      "Iteration 650 || Loss: 5.7732 || 10iter: 439.3180 sec\n",
      "Iteration 660 || Loss: 6.0164 || 10iter: 438.9664 sec\n",
      "Iteration 670 || Loss: 6.2588 || 10iter: 439.2054 sec\n",
      "Iteration 680 || Loss: 6.4045 || 10iter: 446.8253 sec\n",
      "Iteration 690 || Loss: 6.3477 || 10iter: 440.2897 sec\n",
      "Iteration 700 || Loss: 6.5357 || 10iter: 442.3181 sec\n",
      "Iteration 710 || Loss: 6.6822 || 10iter: 441.0916 sec\n",
      "------------------------------------------------------------\n",
      "Epoch 4 || epoch_train_loss: 1137.4772 || Epoch_val_loss: 0.0000\n",
      "Duration: 7885.9186 sec\n",
      "------------------------------------------------------------\n",
      "Epoch 5/30\n",
      "------------------------------------------------------------\n",
      "(Training)\n",
      "Iteration 720 || Loss: 6.4278 || 10iter: 176.3195 sec\n",
      "Iteration 730 || Loss: 6.0394 || 10iter: 440.0268 sec\n",
      "Iteration 740 || Loss: 6.1625 || 10iter: 438.2143 sec\n",
      "Iteration 750 || Loss: 5.8258 || 10iter: 437.4962 sec\n",
      "Iteration 760 || Loss: 5.9884 || 10iter: 440.8381 sec\n",
      "Iteration 770 || Loss: 6.0839 || 10iter: 440.7763 sec\n",
      "Iteration 780 || Loss: 5.9650 || 10iter: 440.7979 sec\n",
      "Iteration 790 || Loss: 6.4385 || 10iter: 445.3436 sec\n",
      "Iteration 800 || Loss: 6.3160 || 10iter: 439.6722 sec\n",
      "Iteration 810 || Loss: 6.1190 || 10iter: 441.4248 sec\n",
      "Iteration 820 || Loss: 6.4374 || 10iter: 440.1072 sec\n",
      "Iteration 830 || Loss: 5.9318 || 10iter: 441.1260 sec\n",
      "Iteration 840 || Loss: 6.1743 || 10iter: 440.7530 sec\n",
      "Iteration 850 || Loss: 5.8049 || 10iter: 441.4918 sec\n",
      "Iteration 860 || Loss: 6.4224 || 10iter: 438.6554 sec\n",
      "Iteration 870 || Loss: 6.1024 || 10iter: 443.5110 sec\n",
      "Iteration 880 || Loss: 6.1446 || 10iter: 441.1991 sec\n",
      "Iteration 890 || Loss: 6.0804 || 10iter: 441.9388 sec\n",
      "------------------------------------------------------------\n",
      "Epoch 5 || epoch_train_loss: 1084.3871 || Epoch_val_loss: 0.0000\n",
      "Duration: 7875.6155 sec\n",
      "------------------------------------------------------------\n",
      "Epoch 6/30\n",
      "------------------------------------------------------------\n",
      "(Training)\n",
      "Iteration 900 || Loss: 6.0197 || 10iter: 226.3292 sec\n",
      "Iteration 910 || Loss: 5.9968 || 10iter: 444.4869 sec\n",
      "Iteration 920 || Loss: 5.7956 || 10iter: 453.6459 sec\n",
      "Iteration 930 || Loss: 5.9137 || 10iter: 444.7216 sec\n",
      "Iteration 940 || Loss: 5.6884 || 10iter: 442.4704 sec\n",
      "Iteration 950 || Loss: 5.7972 || 10iter: 488.9202 sec\n",
      "Iteration 960 || Loss: 5.9517 || 10iter: 478.6175 sec\n",
      "Iteration 970 || Loss: 5.9454 || 10iter: 499.3475 sec\n",
      "Iteration 980 || Loss: 5.7002 || 10iter: 482.1444 sec\n",
      "Iteration 990 || Loss: 5.9065 || 10iter: 476.7880 sec\n",
      "Iteration 1000 || Loss: 5.9831 || 10iter: 2438.3345 sec\n",
      "Iteration 1010 || Loss: 5.8262 || 10iter: 568.3955 sec\n",
      "Iteration 1020 || Loss: 6.0198 || 10iter: 813.2682 sec\n",
      "Iteration 1030 || Loss: 5.8259 || 10iter: 838.5278 sec\n",
      "Iteration 1040 || Loss: 5.7788 || 10iter: 835.1390 sec\n",
      "Iteration 1050 || Loss: 5.6386 || 10iter: 838.9583 sec\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 30\n",
    "train_model(net, dataloader_dict, criterion, optimizer, num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe12565c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
