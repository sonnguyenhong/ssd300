{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03038747",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run lib.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7048ab85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5717\n",
      ".\\data\\VOCdevkit\\VOC2012\\JPEGImages\\2008_000008.jpg\n"
     ]
    }
   ],
   "source": [
    "%run make_datapath.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "baf4bda6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5717\n",
      ".\\data\\VOCdevkit\\VOC2012\\JPEGImages\\2008_000008.jpg\n",
      "5717\n",
      ".\\data\\VOCdevkit\\VOC2012\\JPEGImages\\2008_000008.jpg\n",
      "[[ 0.09        0.03003003  0.998       0.996997   18.        ]\n",
      " [ 0.122       0.56756757  0.164       0.72672673 14.        ]]\n",
      "5717\n",
      ".\\data\\VOCdevkit\\VOC2012\\JPEGImages\\2008_000008.jpg\n",
      "[[ 0.09        0.03003003  0.998       0.996997   18.        ]\n",
      " [ 0.122       0.56756757  0.164       0.72672673 14.        ]]\n",
      "torch.Size([4, 3, 300, 300])\n",
      "4\n",
      "torch.Size([1, 5])\n"
     ]
    }
   ],
   "source": [
    "%run dataset.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df35419f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5717\n",
      ".\\data\\VOCdevkit\\VOC2012\\JPEGImages\\2008_000008.jpg\n",
      "5717\n",
      ".\\data\\VOCdevkit\\VOC2012\\JPEGImages\\2008_000008.jpg\n",
      "[[ 0.09        0.03003003  0.998       0.996997   18.        ]\n",
      " [ 0.122       0.56756757  0.164       0.72672673 14.        ]]\n"
     ]
    }
   ],
   "source": [
    "%run transform.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9c41a13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5717\n",
      ".\\data\\VOCdevkit\\VOC2012\\JPEGImages\\2008_000008.jpg\n",
      "[[ 0.09        0.03003003  0.998       0.996997   18.        ]\n",
      " [ 0.122       0.56756757  0.164       0.72672673 14.        ]]\n"
     ]
    }
   ],
   "source": [
    "%run extract_infor_annotation.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82dee7ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8732, 4])\n",
      "SSD(\n",
      "  (vgg): ModuleList(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU(inplace=True)\n",
      "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU(inplace=True)\n",
      "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU(inplace=True)\n",
      "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): ReLU(inplace=True)\n",
      "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (20): ReLU(inplace=True)\n",
      "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (22): ReLU(inplace=True)\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): ReLU(inplace=True)\n",
      "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (27): ReLU(inplace=True)\n",
      "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (29): ReLU(inplace=True)\n",
      "    (30): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "    (31): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6))\n",
      "    (32): ReLU(inplace=True)\n",
      "    (33): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (34): ReLU(inplace=True)\n",
      "  )\n",
      "  (extras): ModuleList(\n",
      "    (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (2): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (3): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (4): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (5): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (6): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (7): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "  )\n",
      "  (loc): ModuleList(\n",
      "    (0): Conv2d(512, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): Conv2d(1024, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (2): Conv2d(512, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): Conv2d(256, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): Conv2d(256, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (5): Conv2d(256, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (conf): ModuleList(\n",
      "    (0): Conv2d(512, 84, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): Conv2d(1024, 126, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (2): Conv2d(512, 126, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): Conv2d(256, 126, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): Conv2d(256, 84, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (5): Conv2d(256, 84, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (L2Norm): L2Norm()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "%run model.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bbfab93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run multiboxloss.ipynb\n",
    "%run utils/augmentation.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23d6fca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device:\", device)\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1227e9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloader\n",
    "root_path = \"./data/VOCdevkit/VOC2012\"\n",
    "train_img_list, train_anno_list, val_img_list, val_anno_list = make_datapath_list(root_path)\n",
    "\n",
    "classes = [\"aeroplane\", \"bicycle\", \"bird\",  \"boat\", \"bottle\", \n",
    "    \"bus\", \"car\", \"cat\", \"chair\", \"cow\", \"diningtable\",\n",
    "    \"dog\", \"horse\", \"motorbike\", \"person\", \"pottedplant\",\n",
    "    \"sheep\", \"sofa\", \"train\", \"tvmonitor\"]\n",
    "\n",
    "color_mean = (104, 117, 123)\n",
    "input_size = 300\n",
    "\n",
    "#img_list, anno_list, phase, transform, anno_xml\n",
    "train_dataset = MyDataset(train_img_list, train_anno_list, phase=\"train\", transform=DataTransform(input_size, color_mean), anno_xml=Anno_xml(classes))\n",
    "val_dataset = MyDataset(val_img_list, val_anno_list, phase=\"val\", transform=DataTransform(input_size, color_mean), anno_xml=Anno_xml(classes))\n",
    "\n",
    "batch_size = 32\n",
    "train_dataloader = data.DataLoader(train_dataset, batch_size, shuffle=True, collate_fn=my_collate_fn)\n",
    "val_dataloader = data.DataLoader(val_dataset, batch_size, shuffle=False, collate_fn=my_collate_fn)\n",
    "dataloader_dict = {\n",
    "    \"train\": train_dataloader, \n",
    "    \"val\": val_dataloader\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "05c19503",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# network\n",
    "cfg = {\n",
    "    \"num_classes\": 21, #VOC data include 20 class + 1 background class\n",
    "    \"input_size\": 300, #SSD300\n",
    "    \"bbox_aspect_num\": [4, 6, 6, 6, 4, 4], # Tỷ lệ khung hình cho source1->source6`\n",
    "    \"feature_maps\": [38, 19, 10, 5, 3, 1],\n",
    "    \"steps\": [8, 16, 32, 64, 100, 300], # Size of default box\n",
    "    \"min_size\": [30, 60, 111, 162, 213, 264], # Size of default box\n",
    "    \"max_size\": [60, 111, 162, 213, 264, 315], # Size of default box\n",
    "    \"aspect_ratios\": [[2], [2,3], [2,3], [2,3], [2], [2]]\n",
    "}\n",
    "\n",
    "net = SSD(phase=\"train\", cfg=cfg)\n",
    "vgg_weights = torch.load(\"./data/weights/vgg16_reducedfc.pth\")\n",
    "net.vgg.load_state_dict(vgg_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "07f9a6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        nn.init.kaiming_normal_(m.weight.data)\n",
    "        if m.bias is not None:\n",
    "            nn.init.constant_(m.bias, 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b4db8c53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleList(\n",
       "  (0): Conv2d(512, 84, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (1): Conv2d(1024, 126, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (2): Conv2d(512, 126, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (3): Conv2d(256, 126, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (4): Conv2d(256, 84, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (5): Conv2d(256, 84, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# He init\n",
    "net.extras.apply(weights_init)\n",
    "net.loc.apply(weights_init)\n",
    "net.conf.apply(weights_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "04eae9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MultiBoxLoss\n",
    "criterion = MultiBoxLoss(jaccard_threshold=0.5, neg_pos=3, device=device)\n",
    "\n",
    "# optimizer\n",
    "optimizer = optim.SGD(net.parameters(), lr=1e-3, momentum=0.9, weight_decay=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b645a80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training, validation\n",
    "def train_model(net, dataloader_dict, criterion, optimizer, num_epochs):\n",
    "    # move network to GPU\n",
    "    net.to(device)\n",
    "\n",
    "    iteration = 1\n",
    "    epoch_train_loss = 0.0\n",
    "    epoch_val_loss = 0.0\n",
    "    logs = []\n",
    "    for epoch in range(num_epochs+1):\n",
    "        t_epoch_start = time.time()\n",
    "        t_iter_start = time.time()\n",
    "        print(\"---\"*20)\n",
    "        print(\"Epoch {}/{}\".format(epoch+1, num_epochs))\n",
    "        print(\"---\"*20)\n",
    "        for phase in [\"train\", \"val\"]:\n",
    "            if phase == \"train\":\n",
    "                net.train()\n",
    "                print(\"(Training)\")\n",
    "            else:\n",
    "                if (epoch+1) % 10 == 0:\n",
    "                    net.eval() \n",
    "                    print(\"---\"*10)\n",
    "                    print(\"(Validation)\")\n",
    "                else:\n",
    "                    continue\n",
    "            for images, targets in dataloader_dict[phase]:\n",
    "                # move to GPU\n",
    "                images = images.to(device)\n",
    "                targets = [ann.to(device) for ann in targets]\n",
    "                # init optimizer\n",
    "                optimizer.zero_grad()\n",
    "                # forward\n",
    "                with torch.set_grad_enabled(phase==\"train\"):\n",
    "                    outputs = net(images)\n",
    "                    loss_l, loss_c = criterion(outputs, targets)\n",
    "                    loss = loss_l + loss_c\n",
    "\n",
    "                    if phase == \"train\":\n",
    "                        loss.backward() # calculate gradient\n",
    "                        nn.utils.clip_grad_value_(net.parameters(), clip_value=2.0)\n",
    "                        optimizer.step() # update parameters\n",
    "\n",
    "                        if (iteration % 10) == 0:\n",
    "                            t_iter_end = time.time()\n",
    "                            duration = t_iter_end - t_iter_start\n",
    "                            print(\"Iteration {} || Loss: {:.4f} || 10iter: {:.4f} sec\".format(iteration, loss.item(), duration))\n",
    "                            t_iter_start = time.time()\n",
    "                        epoch_train_loss += loss.item()\n",
    "                        iteration += 1\n",
    "                    else:\n",
    "                        epoch_val_loss += loss.item()\n",
    "        t_epoch_end = time.time()\n",
    "        print(\"---\"*20)\n",
    "        print(\"Epoch {} || epoch_train_loss: {:.4f} || Epoch_val_loss: {:.4f}\".format(epoch+1, epoch_train_loss, epoch_val_loss))           \n",
    "        print(\"Duration: {:.4f} sec\".format(t_epoch_end - t_epoch_start))\n",
    "        t_epoch_start = time.time()\n",
    "\n",
    "        log_epoch = {\"epoch\": epoch+1, \"train_loss\": epoch_train_loss, \"val_loss\": epoch_val_loss}\n",
    "        logs.append(log_epoch)\n",
    "        df = pd.DataFrame(logs)\n",
    "        df.to_csv(\"./data/ssd_logs.csv\")\n",
    "        epoch_train_loss = 0.0\n",
    "        epoch_val_loss = 0.0\n",
    "        if ((epoch+1) % 10 == 0):\n",
    "            torch.save(net.state_dict(), \"./data/weights/ssd300_\" + str(epoch+1) + \".pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "24c683e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "Epoch 1/30\n",
      "------------------------------------------------------------\n",
      "(Training)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:238: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 10 || Loss: 13.9786 || 10iter: 590.7018 sec\n",
      "Iteration 20 || Loss: 11.8258 || 10iter: 470.5018 sec\n",
      "Iteration 30 || Loss: 11.9142 || 10iter: 454.1413 sec\n",
      "Iteration 40 || Loss: 10.0509 || 10iter: 485.2065 sec\n",
      "Iteration 50 || Loss: 8.4861 || 10iter: 501.8508 sec\n",
      "Iteration 60 || Loss: 7.7305 || 10iter: 5503.9769 sec\n",
      "Iteration 70 || Loss: 8.0202 || 10iter: 453.5588 sec\n",
      "Iteration 80 || Loss: 7.5931 || 10iter: 3277.7980 sec\n",
      "Iteration 90 || Loss: 7.9180 || 10iter: 610.3388 sec\n",
      "Iteration 100 || Loss: 7.9220 || 10iter: 600.7255 sec\n",
      "Iteration 110 || Loss: 7.4615 || 10iter: 527.5931 sec\n",
      "Iteration 120 || Loss: 7.4421 || 10iter: 570.6170 sec\n",
      "Iteration 130 || Loss: 7.5919 || 10iter: 589.7096 sec\n",
      "Iteration 140 || Loss: 7.6607 || 10iter: 546.1700 sec\n",
      "Iteration 150 || Loss: 7.0752 || 10iter: 529.7249 sec\n",
      "Iteration 160 || Loss: 8.2080 || 10iter: 448.2675 sec\n",
      "Iteration 170 || Loss: 8.8018 || 10iter: 448.8072 sec\n",
      "------------------------------------------------------------\n",
      "Epoch 1 || epoch_train_loss: 1649.8066 || Epoch_val_loss: 0.0000\n",
      "Duration: 17000.2642 sec\n",
      "------------------------------------------------------------\n",
      "Epoch 2/30\n",
      "------------------------------------------------------------\n",
      "(Training)\n",
      "Iteration 180 || Loss: 8.1318 || 10iter: 43.7287 sec\n",
      "Iteration 190 || Loss: 7.2438 || 10iter: 506.7360 sec\n",
      "Iteration 200 || Loss: 7.2719 || 10iter: 489.0254 sec\n",
      "Iteration 210 || Loss: 7.3572 || 10iter: 542.3655 sec\n",
      "Iteration 220 || Loss: 7.7027 || 10iter: 510.7581 sec\n",
      "Iteration 230 || Loss: 7.1026 || 10iter: 546.2045 sec\n",
      "Iteration 240 || Loss: 7.0504 || 10iter: 473.5813 sec\n",
      "Iteration 250 || Loss: 7.0893 || 10iter: 481.9501 sec\n",
      "Iteration 260 || Loss: 7.1214 || 10iter: 475.2217 sec\n",
      "Iteration 270 || Loss: 7.5887 || 10iter: 462.9350 sec\n",
      "Iteration 280 || Loss: 6.9979 || 10iter: 451.3122 sec\n",
      "Iteration 290 || Loss: 7.1080 || 10iter: 444.8787 sec\n",
      "Iteration 300 || Loss: 6.4359 || 10iter: 443.8805 sec\n",
      "Iteration 310 || Loss: 6.9727 || 10iter: 450.6423 sec\n",
      "Iteration 320 || Loss: 7.4941 || 10iter: 437.6200 sec\n",
      "Iteration 330 || Loss: 7.4753 || 10iter: 447.6949 sec\n",
      "Iteration 340 || Loss: 7.0518 || 10iter: 439.3225 sec\n",
      "Iteration 350 || Loss: 6.6630 || 10iter: 438.8509 sec\n",
      "------------------------------------------------------------\n",
      "Epoch 2 || epoch_train_loss: 1308.7023 || Epoch_val_loss: 0.0000\n",
      "Duration: 8423.3918 sec\n",
      "------------------------------------------------------------\n",
      "Epoch 3/30\n",
      "------------------------------------------------------------\n",
      "(Training)\n",
      "Iteration 360 || Loss: 7.1667 || 10iter: 87.6290 sec\n",
      "Iteration 370 || Loss: 7.4962 || 10iter: 439.5008 sec\n",
      "Iteration 380 || Loss: 6.7585 || 10iter: 442.2554 sec\n",
      "Iteration 390 || Loss: 6.8881 || 10iter: 439.2237 sec\n",
      "Iteration 400 || Loss: 7.2322 || 10iter: 439.6125 sec\n",
      "Iteration 410 || Loss: 7.3320 || 10iter: 438.9335 sec\n",
      "Iteration 420 || Loss: 6.6390 || 10iter: 438.5288 sec\n",
      "Iteration 430 || Loss: 7.0474 || 10iter: 436.7846 sec\n",
      "Iteration 440 || Loss: 6.5716 || 10iter: 440.1676 sec\n",
      "Iteration 450 || Loss: 6.6482 || 10iter: 438.3942 sec\n",
      "Iteration 460 || Loss: 6.5161 || 10iter: 441.2287 sec\n",
      "Iteration 470 || Loss: 6.5315 || 10iter: 437.2409 sec\n",
      "Iteration 480 || Loss: 6.7035 || 10iter: 438.7763 sec\n",
      "Iteration 490 || Loss: 7.4042 || 10iter: 438.0739 sec\n",
      "Iteration 500 || Loss: 6.4565 || 10iter: 439.2639 sec\n",
      "Iteration 510 || Loss: 6.6448 || 10iter: 438.0875 sec\n",
      "Iteration 520 || Loss: 6.6692 || 10iter: 438.8025 sec\n",
      "Iteration 530 || Loss: 6.4930 || 10iter: 435.8348 sec\n",
      "------------------------------------------------------------\n",
      "Epoch 3 || epoch_train_loss: 1215.6965 || Epoch_val_loss: 0.0000\n",
      "Duration: 7842.5981 sec\n",
      "------------------------------------------------------------\n",
      "Epoch 4/30\n",
      "------------------------------------------------------------\n",
      "(Training)\n",
      "Iteration 540 || Loss: 6.3582 || 10iter: 132.4652 sec\n",
      "Iteration 550 || Loss: 6.2169 || 10iter: 439.6896 sec\n",
      "Iteration 560 || Loss: 6.8566 || 10iter: 439.5743 sec\n",
      "Iteration 570 || Loss: 6.4005 || 10iter: 439.4009 sec\n",
      "Iteration 580 || Loss: 6.6981 || 10iter: 439.4313 sec\n",
      "Iteration 590 || Loss: 6.3402 || 10iter: 440.1005 sec\n",
      "Iteration 600 || Loss: 6.6739 || 10iter: 454.6336 sec\n",
      "Iteration 610 || Loss: 6.7102 || 10iter: 441.2576 sec\n",
      "Iteration 620 || Loss: 6.2306 || 10iter: 442.4958 sec\n",
      "Iteration 630 || Loss: 6.3211 || 10iter: 441.7174 sec\n",
      "Iteration 640 || Loss: 6.2763 || 10iter: 437.9137 sec\n",
      "Iteration 650 || Loss: 5.7732 || 10iter: 439.3180 sec\n",
      "Iteration 660 || Loss: 6.0164 || 10iter: 438.9664 sec\n",
      "Iteration 670 || Loss: 6.2588 || 10iter: 439.2054 sec\n",
      "Iteration 680 || Loss: 6.4045 || 10iter: 446.8253 sec\n",
      "Iteration 690 || Loss: 6.3477 || 10iter: 440.2897 sec\n",
      "Iteration 700 || Loss: 6.5357 || 10iter: 442.3181 sec\n",
      "Iteration 710 || Loss: 6.6822 || 10iter: 441.0916 sec\n",
      "------------------------------------------------------------\n",
      "Epoch 4 || epoch_train_loss: 1137.4772 || Epoch_val_loss: 0.0000\n",
      "Duration: 7885.9186 sec\n",
      "------------------------------------------------------------\n",
      "Epoch 5/30\n",
      "------------------------------------------------------------\n",
      "(Training)\n",
      "Iteration 720 || Loss: 6.4278 || 10iter: 176.3195 sec\n",
      "Iteration 730 || Loss: 6.0394 || 10iter: 440.0268 sec\n",
      "Iteration 740 || Loss: 6.1625 || 10iter: 438.2143 sec\n",
      "Iteration 750 || Loss: 5.8258 || 10iter: 437.4962 sec\n",
      "Iteration 760 || Loss: 5.9884 || 10iter: 440.8381 sec\n",
      "Iteration 770 || Loss: 6.0839 || 10iter: 440.7763 sec\n",
      "Iteration 780 || Loss: 5.9650 || 10iter: 440.7979 sec\n",
      "Iteration 790 || Loss: 6.4385 || 10iter: 445.3436 sec\n",
      "Iteration 800 || Loss: 6.3160 || 10iter: 439.6722 sec\n",
      "Iteration 810 || Loss: 6.1190 || 10iter: 441.4248 sec\n",
      "Iteration 820 || Loss: 6.4374 || 10iter: 440.1072 sec\n",
      "Iteration 830 || Loss: 5.9318 || 10iter: 441.1260 sec\n",
      "Iteration 840 || Loss: 6.1743 || 10iter: 440.7530 sec\n",
      "Iteration 850 || Loss: 5.8049 || 10iter: 441.4918 sec\n",
      "Iteration 860 || Loss: 6.4224 || 10iter: 438.6554 sec\n",
      "Iteration 870 || Loss: 6.1024 || 10iter: 443.5110 sec\n",
      "Iteration 880 || Loss: 6.1446 || 10iter: 441.1991 sec\n",
      "Iteration 890 || Loss: 6.0804 || 10iter: 441.9388 sec\n",
      "------------------------------------------------------------\n",
      "Epoch 5 || epoch_train_loss: 1084.3871 || Epoch_val_loss: 0.0000\n",
      "Duration: 7875.6155 sec\n",
      "------------------------------------------------------------\n",
      "Epoch 6/30\n",
      "------------------------------------------------------------\n",
      "(Training)\n",
      "Iteration 900 || Loss: 6.0197 || 10iter: 226.3292 sec\n",
      "Iteration 910 || Loss: 5.9968 || 10iter: 444.4869 sec\n",
      "Iteration 920 || Loss: 5.7956 || 10iter: 453.6459 sec\n",
      "Iteration 930 || Loss: 5.9137 || 10iter: 444.7216 sec\n",
      "Iteration 940 || Loss: 5.6884 || 10iter: 442.4704 sec\n",
      "Iteration 950 || Loss: 5.7972 || 10iter: 488.9202 sec\n",
      "Iteration 960 || Loss: 5.9517 || 10iter: 478.6175 sec\n",
      "Iteration 970 || Loss: 5.9454 || 10iter: 499.3475 sec\n",
      "Iteration 980 || Loss: 5.7002 || 10iter: 482.1444 sec\n",
      "Iteration 990 || Loss: 5.9065 || 10iter: 476.7880 sec\n",
      "Iteration 1000 || Loss: 5.9831 || 10iter: 2438.3345 sec\n",
      "Iteration 1010 || Loss: 5.8262 || 10iter: 568.3955 sec\n",
      "Iteration 1020 || Loss: 6.0198 || 10iter: 813.2682 sec\n",
      "Iteration 1030 || Loss: 5.8259 || 10iter: 838.5278 sec\n",
      "Iteration 1040 || Loss: 5.7788 || 10iter: 835.1390 sec\n",
      "Iteration 1050 || Loss: 5.6386 || 10iter: 838.9583 sec\n",
      "Iteration 1060 || Loss: 5.8805 || 10iter: 840.0447 sec\n",
      "Iteration 1070 || Loss: 5.6877 || 10iter: 844.9363 sec\n",
      "------------------------------------------------------------\n",
      "Epoch 6 || epoch_train_loss: 1042.5851 || Epoch_val_loss: 0.0000\n",
      "Duration: 12762.3000 sec\n",
      "------------------------------------------------------------\n",
      "Epoch 7/30\n",
      "------------------------------------------------------------\n",
      "(Training)\n",
      "Iteration 1080 || Loss: 5.7799 || 10iter: 482.1977 sec\n",
      "Iteration 1090 || Loss: 5.5679 || 10iter: 820.7997 sec\n",
      "Iteration 1100 || Loss: 5.8938 || 10iter: 549.8567 sec\n",
      "Iteration 1110 || Loss: 5.3193 || 10iter: 481.6342 sec\n",
      "Iteration 1120 || Loss: 5.1270 || 10iter: 474.8949 sec\n",
      "Iteration 1130 || Loss: 5.4434 || 10iter: 529.5746 sec\n",
      "Iteration 1140 || Loss: 5.5298 || 10iter: 539.6020 sec\n",
      "Iteration 1150 || Loss: 5.5712 || 10iter: 509.8618 sec\n",
      "Iteration 1160 || Loss: 5.5186 || 10iter: 473.6768 sec\n",
      "Iteration 1170 || Loss: 5.3712 || 10iter: 469.6734 sec\n",
      "Iteration 1180 || Loss: 6.0637 || 10iter: 462.1788 sec\n",
      "Iteration 1190 || Loss: 5.8228 || 10iter: 459.0813 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1200 || Loss: 5.6359 || 10iter: 499.7130 sec\n",
      "Iteration 1210 || Loss: 5.8819 || 10iter: 488.9944 sec\n",
      "Iteration 1220 || Loss: 5.6347 || 10iter: 463.2631 sec\n",
      "Iteration 1230 || Loss: 5.8228 || 10iter: 457.1816 sec\n",
      "Iteration 1240 || Loss: 5.8953 || 10iter: 528.6156 sec\n",
      "Iteration 1250 || Loss: 5.6431 || 10iter: 541.7407 sec\n",
      "------------------------------------------------------------\n",
      "Epoch 7 || epoch_train_loss: 1010.0641 || Epoch_val_loss: 0.0000\n",
      "Duration: 9363.8852 sec\n",
      "------------------------------------------------------------\n",
      "Epoch 8/30\n",
      "------------------------------------------------------------\n",
      "(Training)\n",
      "Iteration 1260 || Loss: 5.3497 || 10iter: 334.1845 sec\n",
      "Iteration 1270 || Loss: 6.1366 || 10iter: 469.7867 sec\n",
      "Iteration 1280 || Loss: 5.4393 || 10iter: 469.5996 sec\n",
      "Iteration 1290 || Loss: 5.2509 || 10iter: 514.0397 sec\n",
      "Iteration 1300 || Loss: 5.5637 || 10iter: 592.5029 sec\n",
      "Iteration 1310 || Loss: 5.4661 || 10iter: 585.0431 sec\n",
      "Iteration 1320 || Loss: 5.4588 || 10iter: 601.2700 sec\n",
      "Iteration 1330 || Loss: 5.4031 || 10iter: 517.5605 sec\n",
      "Iteration 1340 || Loss: 5.7345 || 10iter: 541.8929 sec\n",
      "Iteration 1350 || Loss: 5.5950 || 10iter: 552.7319 sec\n",
      "Iteration 1360 || Loss: 5.5684 || 10iter: 558.3066 sec\n",
      "Iteration 1370 || Loss: 5.3348 || 10iter: 543.7784 sec\n",
      "Iteration 1380 || Loss: 5.5846 || 10iter: 519.1387 sec\n",
      "Iteration 1390 || Loss: 5.3527 || 10iter: 562.5027 sec\n",
      "Iteration 1400 || Loss: 5.2367 || 10iter: 543.5715 sec\n",
      "Iteration 1410 || Loss: 5.5352 || 10iter: 608.7502 sec\n",
      "Iteration 1420 || Loss: 5.3622 || 10iter: 554.9948 sec\n",
      "Iteration 1430 || Loss: 5.6178 || 10iter: 544.4557 sec\n",
      "------------------------------------------------------------\n",
      "Epoch 8 || epoch_train_loss: 979.1958 || Epoch_val_loss: 0.0000\n",
      "Duration: 9704.5790 sec\n",
      "------------------------------------------------------------\n",
      "Epoch 9/30\n",
      "------------------------------------------------------------\n",
      "(Training)\n",
      "Iteration 1440 || Loss: 5.4312 || 10iter: 447.0965 sec\n",
      "Iteration 1450 || Loss: 5.2626 || 10iter: 517.0954 sec\n",
      "Iteration 1460 || Loss: 5.6638 || 10iter: 627.3469 sec\n",
      "Iteration 1470 || Loss: 5.4467 || 10iter: 571.9779 sec\n",
      "Iteration 1480 || Loss: 5.4938 || 10iter: 542.5482 sec\n",
      "Iteration 1490 || Loss: 4.9546 || 10iter: 543.2010 sec\n",
      "Iteration 1500 || Loss: 5.4848 || 10iter: 548.3048 sec\n",
      "Iteration 1510 || Loss: 5.3051 || 10iter: 546.5799 sec\n",
      "Iteration 1520 || Loss: 5.1081 || 10iter: 546.5231 sec\n",
      "Iteration 1530 || Loss: 5.3382 || 10iter: 550.6320 sec\n",
      "Iteration 1540 || Loss: 5.2829 || 10iter: 533.5581 sec\n",
      "Iteration 1550 || Loss: 5.1935 || 10iter: 549.5759 sec\n",
      "Iteration 1560 || Loss: 5.1782 || 10iter: 562.5243 sec\n",
      "Iteration 1570 || Loss: 5.7652 || 10iter: 546.6630 sec\n",
      "Iteration 1580 || Loss: 5.1656 || 10iter: 557.7782 sec\n",
      "Iteration 1590 || Loss: 5.1459 || 10iter: 564.4821 sec\n",
      "Iteration 1600 || Loss: 5.6877 || 10iter: 559.8336 sec\n",
      "Iteration 1610 || Loss: 5.4443 || 10iter: 572.6585 sec\n",
      "------------------------------------------------------------\n",
      "Epoch 9 || epoch_train_loss: 951.7968 || Epoch_val_loss: 0.0000\n",
      "Duration: 15039.7594 sec\n",
      "------------------------------------------------------------\n",
      "Epoch 10/30\n",
      "------------------------------------------------------------\n",
      "(Training)\n",
      "Iteration 1620 || Loss: 5.7667 || 10iter: 724.4454 sec\n",
      "Iteration 1630 || Loss: 4.7022 || 10iter: 887.8367 sec\n",
      "Iteration 1640 || Loss: 5.4593 || 10iter: 844.3541 sec\n",
      "Iteration 1650 || Loss: 5.2236 || 10iter: 836.8030 sec\n",
      "Iteration 1660 || Loss: 5.1407 || 10iter: 819.3172 sec\n",
      "Iteration 1670 || Loss: 5.1433 || 10iter: 818.0085 sec\n",
      "Iteration 1680 || Loss: 5.3240 || 10iter: 829.6835 sec\n",
      "Iteration 1690 || Loss: 5.7323 || 10iter: 831.6721 sec\n",
      "Iteration 1700 || Loss: 5.3447 || 10iter: 832.3423 sec\n",
      "Iteration 1710 || Loss: 4.8554 || 10iter: 573.1260 sec\n",
      "Iteration 1720 || Loss: 4.8455 || 10iter: 545.8412 sec\n",
      "Iteration 1730 || Loss: 5.0048 || 10iter: 509.7408 sec\n",
      "Iteration 1740 || Loss: 5.0871 || 10iter: 535.6450 sec\n",
      "Iteration 1750 || Loss: 5.0824 || 10iter: 540.1944 sec\n",
      "Iteration 1760 || Loss: 5.2980 || 10iter: 533.3428 sec\n",
      "Iteration 1770 || Loss: 4.9105 || 10iter: 625.7975 sec\n",
      "Iteration 1780 || Loss: 4.8873 || 10iter: 576.9062 sec\n",
      "Iteration 1790 || Loss: 4.5389 || 10iter: 515.4519 sec\n",
      "------------------------------\n",
      "(Validation)\n",
      "------------------------------------------------------------\n",
      "Epoch 10 || epoch_train_loss: 926.1533 || Epoch_val_loss: 943.5874\n",
      "Duration: 15312.0338 sec\n",
      "------------------------------------------------------------\n",
      "Epoch 11/30\n",
      "------------------------------------------------------------\n",
      "(Training)\n",
      "Iteration 1800 || Loss: 4.8241 || 10iter: 445.5762 sec\n",
      "Iteration 1810 || Loss: 5.2227 || 10iter: 446.3779 sec\n",
      "Iteration 1820 || Loss: 4.9403 || 10iter: 444.2260 sec\n",
      "Iteration 1830 || Loss: 4.9324 || 10iter: 445.1038 sec\n",
      "Iteration 1840 || Loss: 4.9771 || 10iter: 445.5117 sec\n",
      "Iteration 1850 || Loss: 4.5992 || 10iter: 445.2312 sec\n",
      "Iteration 1860 || Loss: 4.5220 || 10iter: 445.5303 sec\n",
      "Iteration 1870 || Loss: 5.0525 || 10iter: 445.3537 sec\n",
      "Iteration 1880 || Loss: 4.9803 || 10iter: 442.9358 sec\n",
      "Iteration 1890 || Loss: 4.6719 || 10iter: 445.4760 sec\n",
      "Iteration 1900 || Loss: 4.6690 || 10iter: 445.5759 sec\n",
      "Iteration 1910 || Loss: 5.0746 || 10iter: 443.6289 sec\n",
      "Iteration 1920 || Loss: 4.9897 || 10iter: 442.8647 sec\n",
      "Iteration 1930 || Loss: 4.9619 || 10iter: 449.0233 sec\n",
      "Iteration 1940 || Loss: 4.9723 || 10iter: 458.2607 sec\n",
      "Iteration 1950 || Loss: 4.9646 || 10iter: 446.6374 sec\n",
      "Iteration 1960 || Loss: 4.6182 || 10iter: 442.7210 sec\n",
      "------------------------------------------------------------\n",
      "Epoch 11 || epoch_train_loss: 902.4083 || Epoch_val_loss: 0.0000\n",
      "Duration: 7965.6525 sec\n",
      "------------------------------------------------------------\n",
      "Epoch 12/30\n",
      "------------------------------------------------------------\n",
      "(Training)\n",
      "Iteration 1970 || Loss: 5.2852 || 10iter: 44.4795 sec\n",
      "Iteration 1980 || Loss: 5.0489 || 10iter: 443.7738 sec\n",
      "Iteration 1990 || Loss: 5.5177 || 10iter: 443.1409 sec\n",
      "Iteration 2000 || Loss: 5.0334 || 10iter: 442.1173 sec\n",
      "Iteration 2010 || Loss: 4.9937 || 10iter: 443.2393 sec\n",
      "Iteration 2020 || Loss: 4.8126 || 10iter: 452.1002 sec\n",
      "Iteration 2030 || Loss: 4.9224 || 10iter: 444.4295 sec\n",
      "Iteration 2040 || Loss: 4.8221 || 10iter: 445.1523 sec\n",
      "Iteration 2050 || Loss: 5.4591 || 10iter: 443.5518 sec\n",
      "Iteration 2060 || Loss: 4.8751 || 10iter: 443.2132 sec\n",
      "Iteration 2070 || Loss: 4.7839 || 10iter: 442.9904 sec\n",
      "Iteration 2080 || Loss: 4.6879 || 10iter: 444.4939 sec\n",
      "Iteration 2090 || Loss: 4.8832 || 10iter: 443.8602 sec\n",
      "Iteration 2100 || Loss: 4.7867 || 10iter: 446.9139 sec\n",
      "Iteration 2110 || Loss: 4.8704 || 10iter: 443.6815 sec\n",
      "Iteration 2120 || Loss: 4.6633 || 10iter: 444.3791 sec\n",
      "Iteration 2130 || Loss: 4.8088 || 10iter: 443.7982 sec\n",
      "Iteration 2140 || Loss: 4.9320 || 10iter: 443.5401 sec\n",
      "------------------------------------------------------------\n",
      "Epoch 12 || epoch_train_loss: 886.1964 || Epoch_val_loss: 0.0000\n",
      "Duration: 7940.6452 sec\n",
      "------------------------------------------------------------\n",
      "Epoch 13/30\n",
      "------------------------------------------------------------\n",
      "(Training)\n",
      "Iteration 2150 || Loss: 5.2334 || 10iter: 88.9064 sec\n",
      "Iteration 2160 || Loss: 4.7413 || 10iter: 442.3768 sec\n",
      "Iteration 2170 || Loss: 5.0823 || 10iter: 444.6229 sec\n",
      "Iteration 2180 || Loss: 4.9877 || 10iter: 444.8099 sec\n",
      "Iteration 2190 || Loss: 4.9612 || 10iter: 444.2604 sec\n",
      "Iteration 2200 || Loss: 4.7535 || 10iter: 443.1560 sec\n",
      "Iteration 2210 || Loss: 4.7232 || 10iter: 444.3780 sec\n",
      "Iteration 2220 || Loss: 4.7470 || 10iter: 442.3975 sec\n",
      "Iteration 2230 || Loss: 4.4709 || 10iter: 444.0075 sec\n",
      "Iteration 2240 || Loss: 4.9322 || 10iter: 443.1182 sec\n",
      "Iteration 2250 || Loss: 4.9501 || 10iter: 442.9100 sec\n",
      "Iteration 2260 || Loss: 4.5290 || 10iter: 445.2247 sec\n",
      "Iteration 2270 || Loss: 5.1129 || 10iter: 444.0989 sec\n",
      "Iteration 2280 || Loss: 4.8817 || 10iter: 444.0782 sec\n",
      "Iteration 2290 || Loss: 4.9082 || 10iter: 444.0035 sec\n",
      "Iteration 2300 || Loss: 4.3524 || 10iter: 442.1320 sec\n",
      "Iteration 2310 || Loss: 4.6170 || 10iter: 443.2956 sec\n",
      "Iteration 2320 || Loss: 4.4556 || 10iter: 453.3496 sec\n",
      "------------------------------------------------------------\n",
      "Epoch 13 || epoch_train_loss: 861.1866 || Epoch_val_loss: 0.0000\n",
      "Duration: 7937.5890 sec\n",
      "------------------------------------------------------------\n",
      "Epoch 14/30\n",
      "------------------------------------------------------------\n",
      "(Training)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2330 || Loss: 5.0909 || 10iter: 132.8919 sec\n",
      "Iteration 2340 || Loss: 4.5417 || 10iter: 448.0674 sec\n",
      "Iteration 2350 || Loss: 4.9058 || 10iter: 446.2590 sec\n",
      "Iteration 2360 || Loss: 4.9820 || 10iter: 446.3496 sec\n",
      "Iteration 2370 || Loss: 4.6940 || 10iter: 445.5308 sec\n",
      "Iteration 2380 || Loss: 4.9069 || 10iter: 444.6852 sec\n",
      "Iteration 2390 || Loss: 4.9435 || 10iter: 446.8848 sec\n",
      "Iteration 2400 || Loss: 4.6683 || 10iter: 445.5661 sec\n",
      "Iteration 2410 || Loss: 4.6427 || 10iter: 445.9157 sec\n",
      "Iteration 2420 || Loss: 5.1169 || 10iter: 446.2634 sec\n",
      "Iteration 2430 || Loss: 4.8300 || 10iter: 446.3721 sec\n",
      "Iteration 2440 || Loss: 4.9427 || 10iter: 447.6755 sec\n",
      "Iteration 2450 || Loss: 4.2735 || 10iter: 446.2807 sec\n",
      "Iteration 2460 || Loss: 4.5549 || 10iter: 446.0612 sec\n",
      "Iteration 2470 || Loss: 4.8694 || 10iter: 445.4319 sec\n",
      "Iteration 2480 || Loss: 4.6864 || 10iter: 445.5392 sec\n",
      "Iteration 2490 || Loss: 4.1771 || 10iter: 446.1700 sec\n",
      "Iteration 2500 || Loss: 4.7147 || 10iter: 455.6794 sec\n",
      "------------------------------------------------------------\n",
      "Epoch 14 || epoch_train_loss: 847.9556 || Epoch_val_loss: 0.0000\n",
      "Duration: 7986.1941 sec\n",
      "------------------------------------------------------------\n",
      "Epoch 15/30\n",
      "------------------------------------------------------------\n",
      "(Training)\n",
      "Iteration 2510 || Loss: 4.3653 || 10iter: 178.7992 sec\n",
      "Iteration 2520 || Loss: 4.6022 || 10iter: 450.8430 sec\n",
      "Iteration 2530 || Loss: 5.2380 || 10iter: 447.1837 sec\n",
      "Iteration 2540 || Loss: 5.1683 || 10iter: 447.0817 sec\n",
      "Iteration 2550 || Loss: 4.4203 || 10iter: 447.8967 sec\n",
      "Iteration 2560 || Loss: 4.8265 || 10iter: 448.3909 sec\n",
      "Iteration 2570 || Loss: 4.2746 || 10iter: 7672.9301 sec\n",
      "Iteration 2580 || Loss: 4.3367 || 10iter: 512.8573 sec\n",
      "Iteration 2590 || Loss: 4.5852 || 10iter: 504.4859 sec\n",
      "Iteration 2600 || Loss: 4.4740 || 10iter: 508.7378 sec\n",
      "Iteration 2610 || Loss: 4.7111 || 10iter: 511.8080 sec\n",
      "Iteration 2620 || Loss: 4.8349 || 10iter: 504.6928 sec\n",
      "Iteration 2630 || Loss: 4.8927 || 10iter: 510.0843 sec\n",
      "Iteration 2640 || Loss: 4.3441 || 10iter: 455.2599 sec\n",
      "Iteration 2650 || Loss: 4.6179 || 10iter: 448.6196 sec\n",
      "Iteration 2660 || Loss: 4.2489 || 10iter: 449.5238 sec\n",
      "Iteration 2670 || Loss: 4.8193 || 10iter: 448.8798 sec\n",
      "Iteration 2680 || Loss: 4.5495 || 10iter: 447.4284 sec\n",
      "------------------------------------------------------------\n",
      "Epoch 15 || epoch_train_loss: 834.5389 || Epoch_val_loss: 0.0000\n",
      "Duration: 15604.8183 sec\n",
      "------------------------------------------------------------\n",
      "Epoch 16/30\n",
      "------------------------------------------------------------\n",
      "(Training)\n",
      "Iteration 2690 || Loss: 4.6705 || 10iter: 223.3635 sec\n",
      "Iteration 2700 || Loss: 4.5508 || 10iter: 444.8412 sec\n",
      "Iteration 2710 || Loss: 4.2491 || 10iter: 443.9409 sec\n",
      "Iteration 2720 || Loss: 4.4914 || 10iter: 445.0921 sec\n",
      "Iteration 2730 || Loss: 4.8138 || 10iter: 445.4395 sec\n",
      "Iteration 2740 || Loss: 4.4846 || 10iter: 444.8726 sec\n",
      "Iteration 2750 || Loss: 4.3559 || 10iter: 444.3826 sec\n",
      "Iteration 2760 || Loss: 5.2455 || 10iter: 443.1048 sec\n",
      "Iteration 2770 || Loss: 5.2824 || 10iter: 461.1199 sec\n",
      "Iteration 2780 || Loss: 4.9077 || 10iter: 484.4274 sec\n",
      "Iteration 2790 || Loss: 4.6900 || 10iter: 448.5429 sec\n",
      "Iteration 2800 || Loss: 4.1621 || 10iter: 474.6738 sec\n",
      "Iteration 2810 || Loss: 4.5494 || 10iter: 527.8867 sec\n",
      "Iteration 2820 || Loss: 4.6165 || 10iter: 491.7736 sec\n",
      "Iteration 2830 || Loss: 4.4950 || 10iter: 532.2780 sec\n",
      "Iteration 2840 || Loss: 4.4882 || 10iter: 449.8938 sec\n",
      "Iteration 2850 || Loss: 4.9157 || 10iter: 453.1922 sec\n",
      "Iteration 2860 || Loss: 4.1749 || 10iter: 448.3743 sec\n",
      "------------------------------------------------------------\n",
      "Epoch 16 || epoch_train_loss: 818.9718 || Epoch_val_loss: 0.0000\n",
      "Duration: 8271.3396 sec\n",
      "------------------------------------------------------------\n",
      "Epoch 17/30\n",
      "------------------------------------------------------------\n",
      "(Training)\n",
      "Iteration 2870 || Loss: 4.5650 || 10iter: 266.9295 sec\n",
      "Iteration 2880 || Loss: 4.7164 || 10iter: 475.8368 sec\n",
      "Iteration 2890 || Loss: 4.5197 || 10iter: 533.4742 sec\n",
      "Iteration 2900 || Loss: 4.0727 || 10iter: 505.4045 sec\n",
      "Iteration 2910 || Loss: 4.1371 || 10iter: 484.3531 sec\n",
      "Iteration 2920 || Loss: 4.5264 || 10iter: 466.3917 sec\n",
      "Iteration 2930 || Loss: 4.8444 || 10iter: 491.7754 sec\n",
      "Iteration 2940 || Loss: 4.1946 || 10iter: 457.5541 sec\n",
      "Iteration 2950 || Loss: 4.2796 || 10iter: 493.2221 sec\n",
      "Iteration 2960 || Loss: 4.8836 || 10iter: 475.3172 sec\n",
      "Iteration 2970 || Loss: 4.8704 || 10iter: 483.8553 sec\n",
      "Iteration 2980 || Loss: 4.5796 || 10iter: 470.4611 sec\n",
      "Iteration 2990 || Loss: 4.6159 || 10iter: 451.1093 sec\n",
      "Iteration 3000 || Loss: 4.1118 || 10iter: 447.2562 sec\n",
      "Iteration 3010 || Loss: 4.8620 || 10iter: 448.8568 sec\n",
      "Iteration 3020 || Loss: 4.9604 || 10iter: 448.6062 sec\n",
      "Iteration 3030 || Loss: 4.6383 || 10iter: 450.6801 sec\n",
      "Iteration 3040 || Loss: 4.9531 || 10iter: 448.2240 sec\n",
      "------------------------------------------------------------\n",
      "Epoch 17 || epoch_train_loss: 813.3937 || Epoch_val_loss: 0.0000\n",
      "Duration: 8418.8040 sec\n",
      "------------------------------------------------------------\n",
      "Epoch 18/30\n",
      "------------------------------------------------------------\n",
      "(Training)\n",
      "Iteration 3050 || Loss: 4.6347 || 10iter: 313.6928 sec\n",
      "Iteration 3060 || Loss: 4.5539 || 10iter: 446.9688 sec\n",
      "Iteration 3070 || Loss: 4.5106 || 10iter: 448.7923 sec\n",
      "Iteration 3080 || Loss: 4.3536 || 10iter: 450.2159 sec\n",
      "Iteration 3090 || Loss: 4.5140 || 10iter: 449.6793 sec\n",
      "Iteration 3100 || Loss: 4.9310 || 10iter: 448.6319 sec\n",
      "Iteration 3110 || Loss: 4.8635 || 10iter: 450.4378 sec\n",
      "Iteration 3120 || Loss: 4.5038 || 10iter: 447.7726 sec\n",
      "Iteration 3130 || Loss: 4.2921 || 10iter: 448.6260 sec\n",
      "Iteration 3140 || Loss: 4.6883 || 10iter: 448.7831 sec\n",
      "Iteration 3150 || Loss: 4.5137 || 10iter: 447.2882 sec\n",
      "Iteration 3160 || Loss: 4.3547 || 10iter: 448.8362 sec\n",
      "Iteration 3170 || Loss: 4.7834 || 10iter: 447.5916 sec\n",
      "Iteration 3180 || Loss: 4.7935 || 10iter: 448.5454 sec\n",
      "Iteration 3190 || Loss: 3.8332 || 10iter: 449.2000 sec\n",
      "Iteration 3200 || Loss: 4.2760 || 10iter: 484.6299 sec\n",
      "Iteration 3210 || Loss: 4.7864 || 10iter: 511.9140 sec\n",
      "Iteration 3220 || Loss: 4.7883 || 10iter: 509.4859 sec\n",
      "------------------------------------------------------------\n",
      "Epoch 18 || epoch_train_loss: 799.7828 || Epoch_val_loss: 0.0000\n",
      "Duration: 8175.4394 sec\n",
      "------------------------------------------------------------\n",
      "Epoch 19/30\n",
      "------------------------------------------------------------\n",
      "(Training)\n",
      "Iteration 3230 || Loss: 4.2961 || 10iter: 360.6587 sec\n",
      "Iteration 3240 || Loss: 4.2758 || 10iter: 448.7163 sec\n",
      "Iteration 3250 || Loss: 4.4719 || 10iter: 449.4027 sec\n",
      "Iteration 3260 || Loss: 3.9815 || 10iter: 447.1702 sec\n",
      "Iteration 3270 || Loss: 4.3636 || 10iter: 451.0430 sec\n",
      "Iteration 3280 || Loss: 4.1812 || 10iter: 499.1340 sec\n",
      "Iteration 3290 || Loss: 4.0769 || 10iter: 549.2368 sec\n",
      "Iteration 3300 || Loss: 4.6645 || 10iter: 537.5212 sec\n",
      "Iteration 3310 || Loss: 4.4710 || 10iter: 534.8045 sec\n",
      "Iteration 3320 || Loss: 4.3831 || 10iter: 566.8726 sec\n",
      "Iteration 3330 || Loss: 4.1563 || 10iter: 566.6832 sec\n",
      "Iteration 3340 || Loss: 4.8691 || 10iter: 538.7182 sec\n",
      "Iteration 3350 || Loss: 5.0640 || 10iter: 581.7003 sec\n",
      "Iteration 3360 || Loss: 3.9632 || 10iter: 562.3540 sec\n",
      "Iteration 3370 || Loss: 3.8827 || 10iter: 534.4541 sec\n",
      "Iteration 3380 || Loss: 4.5182 || 10iter: 492.0147 sec\n",
      "Iteration 3390 || Loss: 4.8426 || 10iter: 560.6920 sec\n",
      "Iteration 3400 || Loss: 4.3014 || 10iter: 510.8406 sec\n",
      "------------------------------------------------------------\n",
      "Epoch 19 || epoch_train_loss: 782.6904 || Epoch_val_loss: 0.0000\n",
      "Duration: 9228.7469 sec\n",
      "------------------------------------------------------------\n",
      "Epoch 20/30\n",
      "------------------------------------------------------------\n",
      "(Training)\n",
      "Iteration 3410 || Loss: 4.5181 || 10iter: 476.7600 sec\n",
      "Iteration 3420 || Loss: 4.2761 || 10iter: 529.4559 sec\n",
      "Iteration 3430 || Loss: 3.8665 || 10iter: 455.2539 sec\n",
      "Iteration 3440 || Loss: 4.1005 || 10iter: 444.0089 sec\n",
      "Iteration 3450 || Loss: 4.3692 || 10iter: 442.3073 sec\n",
      "Iteration 3460 || Loss: 4.9457 || 10iter: 441.9501 sec\n",
      "Iteration 3470 || Loss: 4.0980 || 10iter: 446.8734 sec\n",
      "Iteration 3480 || Loss: 4.2583 || 10iter: 441.9352 sec\n",
      "Iteration 3490 || Loss: 4.2136 || 10iter: 440.8067 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3500 || Loss: 4.2407 || 10iter: 440.2344 sec\n",
      "Iteration 3510 || Loss: 4.7038 || 10iter: 438.5743 sec\n",
      "Iteration 3520 || Loss: 4.1077 || 10iter: 439.5806 sec\n",
      "Iteration 3530 || Loss: 4.0186 || 10iter: 439.3605 sec\n",
      "Iteration 3540 || Loss: 4.6108 || 10iter: 439.3688 sec\n",
      "Iteration 3550 || Loss: 4.5390 || 10iter: 438.7417 sec\n",
      "Iteration 3560 || Loss: 3.7025 || 10iter: 441.2500 sec\n",
      "Iteration 3570 || Loss: 4.4771 || 10iter: 439.6412 sec\n",
      "Iteration 3580 || Loss: 4.4708 || 10iter: 424.4191 sec\n",
      "------------------------------\n",
      "(Validation)\n",
      "------------------------------------------------------------\n",
      "Epoch 20 || epoch_train_loss: 778.1371 || Epoch_val_loss: 793.0571\n",
      "Duration: 10764.3231 sec\n",
      "------------------------------------------------------------\n",
      "Epoch 21/30\n",
      "------------------------------------------------------------\n",
      "(Training)\n",
      "Iteration 3590 || Loss: 4.5603 || 10iter: 438.8048 sec\n",
      "Iteration 3600 || Loss: 4.1020 || 10iter: 439.3543 sec\n",
      "Iteration 3610 || Loss: 4.4116 || 10iter: 437.5573 sec\n",
      "Iteration 3620 || Loss: 4.1962 || 10iter: 438.1408 sec\n",
      "Iteration 3630 || Loss: 4.8290 || 10iter: 439.1406 sec\n",
      "Iteration 3640 || Loss: 4.3475 || 10iter: 437.9606 sec\n",
      "Iteration 3650 || Loss: 3.9759 || 10iter: 439.3441 sec\n",
      "Iteration 3660 || Loss: 4.3017 || 10iter: 439.9145 sec\n",
      "Iteration 3670 || Loss: 4.8369 || 10iter: 439.2370 sec\n",
      "Iteration 3680 || Loss: 4.4353 || 10iter: 439.4591 sec\n",
      "Iteration 3690 || Loss: 4.5237 || 10iter: 440.2820 sec\n",
      "Iteration 3700 || Loss: 4.0694 || 10iter: 440.0972 sec\n",
      "Iteration 3710 || Loss: 4.0974 || 10iter: 440.2021 sec\n",
      "Iteration 3720 || Loss: 4.2805 || 10iter: 440.1127 sec\n",
      "Iteration 3730 || Loss: 4.7488 || 10iter: 438.6518 sec\n",
      "Iteration 3740 || Loss: 3.7349 || 10iter: 437.1822 sec\n",
      "Iteration 3750 || Loss: 4.5065 || 10iter: 439.3369 sec\n",
      "------------------------------------------------------------\n",
      "Epoch 21 || epoch_train_loss: 762.4238 || Epoch_val_loss: 0.0000\n",
      "Duration: 7843.7978 sec\n",
      "------------------------------------------------------------\n",
      "Epoch 22/30\n",
      "------------------------------------------------------------\n",
      "(Training)\n",
      "Iteration 3760 || Loss: 3.9062 || 10iter: 43.7556 sec\n",
      "Iteration 3770 || Loss: 4.3699 || 10iter: 442.9269 sec\n",
      "Iteration 3780 || Loss: 4.1096 || 10iter: 445.0446 sec\n",
      "Iteration 3790 || Loss: 4.1958 || 10iter: 436.8302 sec\n",
      "Iteration 3800 || Loss: 4.2306 || 10iter: 438.0336 sec\n",
      "Iteration 3810 || Loss: 4.0854 || 10iter: 437.8538 sec\n",
      "Iteration 3820 || Loss: 4.1157 || 10iter: 438.2978 sec\n",
      "Iteration 3830 || Loss: 4.4218 || 10iter: 440.5282 sec\n",
      "Iteration 3840 || Loss: 4.4774 || 10iter: 437.0557 sec\n",
      "Iteration 3850 || Loss: 4.1968 || 10iter: 437.9592 sec\n",
      "Iteration 3860 || Loss: 4.1587 || 10iter: 436.0131 sec\n",
      "Iteration 3870 || Loss: 4.5236 || 10iter: 446.6623 sec\n",
      "Iteration 3880 || Loss: 4.1950 || 10iter: 441.2853 sec\n",
      "Iteration 3890 || Loss: 3.7944 || 10iter: 440.6761 sec\n",
      "Iteration 3900 || Loss: 4.7641 || 10iter: 439.2970 sec\n",
      "Iteration 3910 || Loss: 4.0891 || 10iter: 442.5710 sec\n",
      "Iteration 3920 || Loss: 3.6333 || 10iter: 440.4841 sec\n",
      "Iteration 3930 || Loss: 4.0366 || 10iter: 441.8072 sec\n",
      "------------------------------------------------------------\n",
      "Epoch 22 || epoch_train_loss: 756.8235 || Epoch_val_loss: 0.0000\n",
      "Duration: 7864.4834 sec\n",
      "------------------------------------------------------------\n",
      "Epoch 23/30\n",
      "------------------------------------------------------------\n",
      "(Training)\n",
      "Iteration 3940 || Loss: 3.9039 || 10iter: 88.2392 sec\n",
      "Iteration 3950 || Loss: 4.0012 || 10iter: 441.1644 sec\n",
      "Iteration 3960 || Loss: 3.8577 || 10iter: 439.9490 sec\n",
      "Iteration 3970 || Loss: 4.0835 || 10iter: 443.2779 sec\n",
      "Iteration 3980 || Loss: 4.2685 || 10iter: 440.6821 sec\n",
      "Iteration 3990 || Loss: 4.4322 || 10iter: 442.1423 sec\n",
      "Iteration 4000 || Loss: 4.2725 || 10iter: 441.1205 sec\n",
      "Iteration 4010 || Loss: 4.5226 || 10iter: 440.9159 sec\n",
      "Iteration 4020 || Loss: 4.8018 || 10iter: 441.4576 sec\n",
      "Iteration 4030 || Loss: 3.9115 || 10iter: 440.3396 sec\n",
      "Iteration 4040 || Loss: 4.1048 || 10iter: 442.0329 sec\n",
      "Iteration 4050 || Loss: 4.5373 || 10iter: 441.3922 sec\n",
      "Iteration 4060 || Loss: 3.9938 || 10iter: 444.4144 sec\n",
      "Iteration 4070 || Loss: 4.1946 || 10iter: 445.3201 sec\n",
      "Iteration 4080 || Loss: 4.1185 || 10iter: 443.6077 sec\n",
      "Iteration 4090 || Loss: 4.0780 || 10iter: 442.8874 sec\n",
      "Iteration 4100 || Loss: 4.4657 || 10iter: 444.1752 sec\n",
      "Iteration 4110 || Loss: 4.1211 || 10iter: 441.8438 sec\n",
      "------------------------------------------------------------\n",
      "Epoch 23 || epoch_train_loss: 746.9422 || Epoch_val_loss: 0.0000\n",
      "Duration: 7899.1578 sec\n",
      "------------------------------------------------------------\n",
      "Epoch 24/30\n",
      "------------------------------------------------------------\n",
      "(Training)\n",
      "Iteration 4120 || Loss: 4.7331 || 10iter: 171.6303 sec\n",
      "Iteration 4130 || Loss: 3.9520 || 10iter: 516.2642 sec\n",
      "Iteration 4140 || Loss: 4.8088 || 10iter: 492.8477 sec\n",
      "Iteration 4150 || Loss: 4.1408 || 10iter: 498.0185 sec\n",
      "Iteration 4160 || Loss: 4.4181 || 10iter: 540.1195 sec\n",
      "Iteration 4170 || Loss: 3.5617 || 10iter: 511.4399 sec\n",
      "Iteration 4180 || Loss: 4.5129 || 10iter: 499.2751 sec\n",
      "Iteration 4190 || Loss: 4.1135 || 10iter: 515.1738 sec\n",
      "Iteration 4200 || Loss: 3.9022 || 10iter: 517.5669 sec\n",
      "Iteration 4210 || Loss: 3.9878 || 10iter: 516.8689 sec\n",
      "Iteration 4220 || Loss: 4.2303 || 10iter: 515.5427 sec\n",
      "Iteration 4230 || Loss: 4.2967 || 10iter: 467.7778 sec\n",
      "Iteration 4240 || Loss: 4.2349 || 10iter: 502.6909 sec\n",
      "Iteration 4250 || Loss: 3.9325 || 10iter: 443.7103 sec\n",
      "Iteration 4260 || Loss: 3.7651 || 10iter: 442.4368 sec\n",
      "Iteration 4270 || Loss: 4.0503 || 10iter: 441.5568 sec\n",
      "Iteration 4280 || Loss: 4.2080 || 10iter: 444.1866 sec\n",
      "Iteration 4290 || Loss: 3.8532 || 10iter: 441.5837 sec\n",
      "------------------------------------------------------------\n",
      "Epoch 24 || epoch_train_loss: 734.7468 || Epoch_val_loss: 0.0000\n",
      "Duration: 8730.2009 sec\n",
      "------------------------------------------------------------\n",
      "Epoch 25/30\n",
      "------------------------------------------------------------\n",
      "(Training)\n",
      "Iteration 4300 || Loss: 4.3304 || 10iter: 176.2153 sec\n",
      "Iteration 4310 || Loss: 4.4953 || 10iter: 449.7961 sec\n",
      "Iteration 4320 || Loss: 4.1261 || 10iter: 440.8482 sec\n",
      "Iteration 4330 || Loss: 4.2886 || 10iter: 441.9904 sec\n",
      "Iteration 4340 || Loss: 3.7497 || 10iter: 442.0540 sec\n",
      "Iteration 4350 || Loss: 4.1963 || 10iter: 440.8177 sec\n",
      "Iteration 4360 || Loss: 4.1315 || 10iter: 441.6864 sec\n",
      "Iteration 4370 || Loss: 3.7509 || 10iter: 440.4813 sec\n",
      "Iteration 4380 || Loss: 4.1945 || 10iter: 449.7167 sec\n",
      "Iteration 4390 || Loss: 3.9787 || 10iter: 440.2162 sec\n",
      "Iteration 4400 || Loss: 4.2537 || 10iter: 441.0434 sec\n",
      "Iteration 4410 || Loss: 3.9614 || 10iter: 441.0986 sec\n",
      "Iteration 4420 || Loss: 3.7165 || 10iter: 442.2242 sec\n",
      "Iteration 4430 || Loss: 4.1364 || 10iter: 440.9899 sec\n",
      "Iteration 4440 || Loss: 4.0805 || 10iter: 441.6432 sec\n",
      "Iteration 4450 || Loss: 3.9932 || 10iter: 440.4659 sec\n",
      "Iteration 4460 || Loss: 4.1807 || 10iter: 445.0771 sec\n",
      "Iteration 4470 || Loss: 4.0408 || 10iter: 441.1041 sec\n",
      "------------------------------------------------------------\n",
      "Epoch 25 || epoch_train_loss: 726.6578 || Epoch_val_loss: 0.0000\n",
      "Duration: 7903.4196 sec\n",
      "------------------------------------------------------------\n",
      "Epoch 26/30\n",
      "------------------------------------------------------------\n",
      "(Training)\n",
      "Iteration 4480 || Loss: 3.9987 || 10iter: 219.7683 sec\n",
      "Iteration 4490 || Loss: 3.8894 || 10iter: 441.5887 sec\n",
      "Iteration 4500 || Loss: 4.3206 || 10iter: 441.1167 sec\n",
      "Iteration 4510 || Loss: 4.1363 || 10iter: 443.1787 sec\n",
      "Iteration 4520 || Loss: 4.1699 || 10iter: 442.5841 sec\n",
      "Iteration 4530 || Loss: 4.4758 || 10iter: 441.3697 sec\n",
      "Iteration 4540 || Loss: 3.7813 || 10iter: 452.5809 sec\n",
      "Iteration 4550 || Loss: 4.0816 || 10iter: 469.3355 sec\n",
      "Iteration 4560 || Loss: 3.8039 || 10iter: 501.3105 sec\n",
      "Iteration 4570 || Loss: 4.2423 || 10iter: 459.5774 sec\n",
      "Iteration 4580 || Loss: 3.6794 || 10iter: 522.4966 sec\n",
      "Iteration 4590 || Loss: 3.7551 || 10iter: 472.6312 sec\n",
      "Iteration 4600 || Loss: 4.0938 || 10iter: 454.8484 sec\n",
      "Iteration 4610 || Loss: 3.9715 || 10iter: 448.2660 sec\n",
      "Iteration 4620 || Loss: 3.8316 || 10iter: 450.2935 sec\n",
      "Iteration 4630 || Loss: 4.0368 || 10iter: 448.2785 sec\n",
      "Iteration 4640 || Loss: 4.4258 || 10iter: 492.7233 sec\n",
      "Iteration 4650 || Loss: 3.5693 || 10iter: 531.3282 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "Epoch 26 || epoch_train_loss: 717.6158 || Epoch_val_loss: 0.0000\n",
      "Duration: 8343.7173 sec\n",
      "------------------------------------------------------------\n",
      "Epoch 27/30\n",
      "------------------------------------------------------------\n",
      "(Training)\n",
      "Iteration 4660 || Loss: 4.0326 || 10iter: 288.5624 sec\n",
      "Iteration 4670 || Loss: 4.0917 || 10iter: 442.8758 sec\n",
      "Iteration 4680 || Loss: 3.6855 || 10iter: 440.6144 sec\n",
      "Iteration 4690 || Loss: 3.9736 || 10iter: 440.6817 sec\n",
      "Iteration 4700 || Loss: 3.8010 || 10iter: 442.0962 sec\n",
      "Iteration 4710 || Loss: 3.7490 || 10iter: 440.3826 sec\n",
      "Iteration 4720 || Loss: 3.5014 || 10iter: 439.6896 sec\n",
      "Iteration 4730 || Loss: 3.8625 || 10iter: 448.2385 sec\n",
      "Iteration 4740 || Loss: 3.9837 || 10iter: 458.4973 sec\n",
      "Iteration 4750 || Loss: 4.0366 || 10iter: 450.0784 sec\n",
      "Iteration 4760 || Loss: 4.0354 || 10iter: 452.0952 sec\n",
      "Iteration 4770 || Loss: 4.3064 || 10iter: 448.8162 sec\n",
      "Iteration 4780 || Loss: 3.7704 || 10iter: 443.4297 sec\n",
      "Iteration 4790 || Loss: 4.3897 || 10iter: 442.0418 sec\n",
      "Iteration 4800 || Loss: 3.9901 || 10iter: 441.0137 sec\n",
      "Iteration 4810 || Loss: 4.0197 || 10iter: 7002.7081 sec\n",
      "Iteration 4820 || Loss: 3.8847 || 10iter: 496.5669 sec\n",
      "Iteration 4830 || Loss: 4.1658 || 10iter: 498.8489 sec\n",
      "------------------------------------------------------------\n",
      "Epoch 27 || epoch_train_loss: 716.5064 || Epoch_val_loss: 0.0000\n",
      "Duration: 14647.7766 sec\n",
      "------------------------------------------------------------\n",
      "Epoch 28/30\n",
      "------------------------------------------------------------\n",
      "(Training)\n",
      "Iteration 4840 || Loss: 3.8138 || 10iter: 349.0571 sec\n",
      "Iteration 4850 || Loss: 3.9227 || 10iter: 496.5283 sec\n",
      "Iteration 4860 || Loss: 4.0269 || 10iter: 493.6570 sec\n",
      "Iteration 4870 || Loss: 4.1000 || 10iter: 534.6135 sec\n",
      "Iteration 4880 || Loss: 3.7660 || 10iter: 496.2991 sec\n",
      "Iteration 4890 || Loss: 3.9821 || 10iter: 494.9790 sec\n",
      "Iteration 4900 || Loss: 3.6144 || 10iter: 491.8484 sec\n",
      "Iteration 4910 || Loss: 3.7059 || 10iter: 492.5007 sec\n",
      "Iteration 4920 || Loss: 3.7725 || 10iter: 497.6367 sec\n",
      "Iteration 4930 || Loss: 3.9416 || 10iter: 482.2964 sec\n",
      "Iteration 4940 || Loss: 4.3994 || 10iter: 444.9271 sec\n",
      "Iteration 4950 || Loss: 4.2901 || 10iter: 438.5731 sec\n",
      "Iteration 4960 || Loss: 3.9394 || 10iter: 499.3269 sec\n",
      "Iteration 4970 || Loss: 4.1566 || 10iter: 507.3981 sec\n",
      "Iteration 4980 || Loss: 4.1976 || 10iter: 599.7271 sec\n",
      "Iteration 4990 || Loss: 3.2968 || 10iter: 552.6152 sec\n",
      "Iteration 5000 || Loss: 3.5310 || 10iter: 530.4986 sec\n",
      "Iteration 5010 || Loss: 3.7312 || 10iter: 535.6637 sec\n",
      "------------------------------------------------------------\n",
      "Epoch 28 || epoch_train_loss: 704.6774 || Epoch_val_loss: 0.0000\n",
      "Duration: 9030.4480 sec\n",
      "------------------------------------------------------------\n",
      "Epoch 29/30\n",
      "------------------------------------------------------------\n",
      "(Training)\n",
      "Iteration 5020 || Loss: 4.1384 || 10iter: 423.6683 sec\n",
      "Iteration 5030 || Loss: 3.8298 || 10iter: 533.0926 sec\n",
      "Iteration 5040 || Loss: 3.6739 || 10iter: 469.4174 sec\n",
      "Iteration 5050 || Loss: 3.7917 || 10iter: 470.1222 sec\n",
      "Iteration 5060 || Loss: 3.4510 || 10iter: 518.7101 sec\n",
      "Iteration 5070 || Loss: 3.9916 || 10iter: 537.0742 sec\n",
      "Iteration 5080 || Loss: 3.6430 || 10iter: 544.0393 sec\n",
      "Iteration 5090 || Loss: 2.9907 || 10iter: 541.6824 sec\n",
      "Iteration 5100 || Loss: 3.8263 || 10iter: 536.4156 sec\n",
      "Iteration 5110 || Loss: 3.7147 || 10iter: 538.7288 sec\n",
      "Iteration 5120 || Loss: 4.0954 || 10iter: 560.0059 sec\n",
      "Iteration 5130 || Loss: 4.0845 || 10iter: 518.5140 sec\n",
      "Iteration 5140 || Loss: 3.8231 || 10iter: 530.2372 sec\n",
      "Iteration 5150 || Loss: 3.8175 || 10iter: 526.4777 sec\n",
      "Iteration 5160 || Loss: 4.0979 || 10iter: 498.8800 sec\n",
      "Iteration 5170 || Loss: 3.9505 || 10iter: 467.4488 sec\n",
      "Iteration 5180 || Loss: 3.7675 || 10iter: 447.0718 sec\n",
      "Iteration 5190 || Loss: 3.4012 || 10iter: 443.2714 sec\n",
      "------------------------------------------------------------\n",
      "Epoch 29 || epoch_train_loss: 692.0174 || Epoch_val_loss: 0.0000\n",
      "Duration: 9134.6728 sec\n",
      "------------------------------------------------------------\n",
      "Epoch 30/30\n",
      "------------------------------------------------------------\n",
      "(Training)\n",
      "Iteration 5200 || Loss: 3.7461 || 10iter: 398.4033 sec\n",
      "Iteration 5210 || Loss: 4.0142 || 10iter: 445.6648 sec\n",
      "Iteration 5220 || Loss: 4.1861 || 10iter: 443.5497 sec\n",
      "Iteration 5230 || Loss: 3.8718 || 10iter: 444.6531 sec\n",
      "Iteration 5240 || Loss: 3.8443 || 10iter: 447.9425 sec\n",
      "Iteration 5250 || Loss: 4.0716 || 10iter: 446.8575 sec\n",
      "Iteration 5260 || Loss: 3.8125 || 10iter: 443.9810 sec\n",
      "Iteration 5270 || Loss: 3.6456 || 10iter: 445.1391 sec\n",
      "Iteration 5280 || Loss: 3.9392 || 10iter: 442.9635 sec\n",
      "Iteration 5290 || Loss: 4.0641 || 10iter: 445.2499 sec\n",
      "Iteration 5300 || Loss: 3.7468 || 10iter: 442.6109 sec\n",
      "Iteration 5310 || Loss: 4.0928 || 10iter: 443.7609 sec\n",
      "Iteration 5320 || Loss: 4.2073 || 10iter: 444.8010 sec\n",
      "Iteration 5330 || Loss: 4.0155 || 10iter: 445.1849 sec\n",
      "Iteration 5340 || Loss: 3.6705 || 10iter: 443.3784 sec\n",
      "Iteration 5350 || Loss: 3.4574 || 10iter: 443.1986 sec\n",
      "Iteration 5360 || Loss: 3.5682 || 10iter: 442.7694 sec\n",
      "Iteration 5370 || Loss: 3.9485 || 10iter: 429.1952 sec\n",
      "------------------------------\n",
      "(Validation)\n",
      "------------------------------------------------------------\n",
      "Epoch 30 || epoch_train_loss: 694.7867 || Epoch_val_loss: 715.4932\n",
      "Duration: 10668.5511 sec\n",
      "------------------------------------------------------------\n",
      "Epoch 31/30\n",
      "------------------------------------------------------------\n",
      "(Training)\n",
      "Iteration 5380 || Loss: 3.4946 || 10iter: 455.8201 sec\n",
      "Iteration 5390 || Loss: 4.2539 || 10iter: 454.2105 sec\n",
      "Iteration 5400 || Loss: 4.0663 || 10iter: 442.6421 sec\n",
      "Iteration 5410 || Loss: 3.4217 || 10iter: 443.1273 sec\n",
      "Iteration 5420 || Loss: 4.0986 || 10iter: 444.0153 sec\n",
      "Iteration 5430 || Loss: 4.2237 || 10iter: 452.1610 sec\n",
      "Iteration 5440 || Loss: 3.8780 || 10iter: 444.5776 sec\n",
      "Iteration 5450 || Loss: 4.4334 || 10iter: 445.5029 sec\n",
      "Iteration 5460 || Loss: 3.6828 || 10iter: 444.6544 sec\n",
      "Iteration 5470 || Loss: 3.5764 || 10iter: 448.6139 sec\n",
      "Iteration 5480 || Loss: 3.1840 || 10iter: 444.7898 sec\n",
      "Iteration 5490 || Loss: 3.9890 || 10iter: 445.3605 sec\n",
      "Iteration 5500 || Loss: 4.3086 || 10iter: 445.7766 sec\n",
      "Iteration 5510 || Loss: 4.0920 || 10iter: 446.1378 sec\n",
      "Iteration 5520 || Loss: 3.6148 || 10iter: 446.5446 sec\n",
      "Iteration 5530 || Loss: 3.6458 || 10iter: 445.8640 sec\n",
      "Iteration 5540 || Loss: 3.7610 || 10iter: 444.3698 sec\n",
      "------------------------------------------------------------\n",
      "Epoch 31 || epoch_train_loss: 685.5084 || Epoch_val_loss: 0.0000\n",
      "Duration: 7979.4405 sec\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 30\n",
    "train_model(net, dataloader_dict, criterion, optimizer, num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4469e568",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
